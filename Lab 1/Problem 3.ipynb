{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "Hara Kumar (19940905-3676)\n",
    "Yeongwoo Kim (19890909-7753)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import maze as mz \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: The Maze and the Random Minotaur\n",
    "\n",
    "The objective is to escape the maze before time T and without getting caught by the minotaur. We start first by describing the maze as a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]\n",
    "])\n",
    "# with the convention \n",
    "# 0 = empty cell\n",
    "# 1 = obstacle\n",
    "# 2 = exit of the Maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `maze.draw_maze()` helps us draw the maze given its numpy array discription.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mz.draw_maze(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP formulation\n",
    "\n",
    "We propose the following MDP formulation: \n",
    "\n",
    "#### State space $\\mathcal{S}$\n",
    "We model the state space as the set of all possible positions of the player and the minotaur in the maze. Note that we exclude states where the player is on an obstacles' position since this is an impossible state. We do, however, permit the player to be in the same position as the minotaur, as this possible (the reward for this state will reflect the fact that this is an undesirable state.\n",
    "\n",
    "$$\\mathcal{S} = \\big\\lbrace (i_a,j_a,i_m,j_m):\\textrm{such that the cell\n",
    "} (i_a,j_a) \\textrm{ is not an obstacle}\\big\\rbrace.$$\n",
    "> **Note:** $\\mathcal i_a and j_a$ represents the position of the agent. $\\mathcal i_m and j_m$ represents the position of the minotaur.\n",
    "\n",
    "#### Action space $\\mathcal{A}$\n",
    "We allow the player to chose to either move `left`, `right`, `down`, `up` or not move at all (`stay`). To prevent duplicate state spaces, actions that would result in the agent encountering a wall or obstacle is excluded from the action space. \n",
    "Formally, the action space is\n",
    "\n",
    "$$\\mathcal{A} = \\lbrace \\textrm{up if }(i_a,(j_a + 1)) \\neq \\textrm{obstacle or wall}, \\\\ \\textrm{ down if } (i_a,(j_a - 1)) \\neq \\textrm{obstacle or wall}, \\\\ \\textrm{ left if } ((i_a - 1),j_a) \\neq \\textrm{obstacle or wall}, \\\\ \\textrm{ right if } ((i_a + 1),j_a) \\neq \\textrm{obstacle or wall}, \\\\ \\textrm{ stay} \\rbrace.$$\n",
    "\n",
    "#### Transition probabilities $\\mathcal{P}$\n",
    "Note that there is no randomness involved upon taking an action by the player. As a consequence, the transition probabilities are deterministic. More precisely,   \n",
    "- If at state (or position) $s$ taking action (or move) $a$ does not lead to a wall or an obstacle but to another state (or position) $s'$, then $\\mathbb{P}(s' \\vert s, a) = 1$. \n",
    "- If at state (or position)  $s$ taking action (or move) $a$ leads to a wall or an obstacle, the player remains in his state (or position) $s$, then $\\mathbb{P}(s \\vert s, a) = 1$.\n",
    "\n",
    "> **Note**: Recall that for a fixed $s \\in \\mathcal{S}$ and $a \\in \\mathcal{A}$ we have $\\sum_{s' \\in \\mathcal{S}} \\mathbb{P}(s' \\vert s, a) = 1$, thus if for some $s' \\in \\mathcal{S}$  we have $\\mathbb{P}(s' \\vert s, a) = 1$, then for all $s'' \\in \\mathcal{S} \\backslash \\lbrace s'\\rbrace$ we have $\\mathbb{P}(s'' \\vert s, a) = 0$,\n",
    "\n",
    "#### Rewards $\\mathcal{R}$\n",
    "The objective of the player is to find the exit of the maze while avoiding the obstacles and the minotaur.    \n",
    "   - If at state $s$, taking action $a$, leads to a wall, obstacle, or the minotaur then $r(s,a) = -\\infty$\n",
    "   - If at state $s$, taking action $a$, leads to some other position in the maze that is not the exit nor a wall nor an obstacle nor the minotaur, then $r(s, a) = -1$. \n",
    "   - If at state $s$, taking action $a$, leads to the exit (without a minotaur) then $r(s ,a) = 0$. \n",
    "> **Note**: Here the rewards are independent of time (i.e. $r_t(.,.) = r(.,.)$). \n",
    "\n",
    "\n",
    "### Implementation\n",
    "The above MDP formulation is implemented as a class ``maze.Maze`` in the file [maze.py](./maze.py) which given a matrix description of the maze instanciates the state space, action space, transition probabilities and rewards. \n",
    "\n",
    "> **Note:** In the class `maze.Maze` each state $s = (i,j)$ is given a unique identifier $s_{id} \\in \\lbrace 0, , \\dots, \\vert S \\vert -1 \\rbrace$. In other words, the state space from an implementation perspective is viewed as the set of integers $\\lbrace 0, , \\dots, \\vert S \\vert -1 \\rbrace$. This mapping is done via the dictionary `self.map` and its inverse mapping via the dictionary `self.states`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment maze\n",
    "env = mz.Maze(maze)\n",
    "# env.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dynamic Programming \n",
    "\n",
    "Before solving the MDP problem, recall that the finite horizon objective function is \n",
    "$$\n",
    "    \\mathbb{E} \\Big[ \\sum_{t=0}^T r(s_t, a_t) \\Big],\n",
    "$$\n",
    "where $T$ is the horizon.\n",
    "Recall the Bellman equation \n",
    "\\begin{equation}\n",
    "\\forall s \\in \\mathcal{S} \\qquad  V(s) = \\max_{a \\in \\mathcal{A}} \\Big\\lbrace r(s,a) + \\sum_{s' \\in \\mathcal{S}} \\mathbb{P}(s'\\vert s,a) V(s') \\Big\\rbrace\n",
    "\\end{equation}\n",
    "The dynamic programming solution for the finite horizon MDP problem consists of solving the above backward recursion. The method `maze.dynamic_programming` achieves this. \n",
    "> **Note:** To find the optimal path, it is enough to set the time horizon $T = 10$. Indeed, looking at the maze one can see that the player needs at least 10 steps to attain the exit $B$, if her starting position is at $A$. In fact if you set the time horizon less than 10, you will see that you do not find the optimal path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite horizon\n",
    "horizon = 20\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy= mz.dynamic_programming(env,horizon);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the shortest path starting from position A\n",
    "method = 'DynProg';\n",
    "start  = (0,0);\n",
    "path = env.simulate(start, policy, method);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration\n",
    "\n",
    "Here we solve the discounted infinite-horizon MDP problem using value iteration, the objective here is to find a stationary policy $\\pi$ that minimizes the infinite horizon objective with a discount factor $\\gamma$ \n",
    "$$\n",
    "    \\mathbb{E} \\Big[\\sum_{t=0}^\\infty \\gamma^t r\\big(s_t, \\pi(s_t)\\big) \\Big].\n",
    "$$\n",
    "Recall the Bellman equation in the case of a stationary policy $\\pi$ \n",
    "\\begin{equation}\n",
    "\\forall s \\in \\mathcal{S} \\qquad  V^*(s) = \\max_{\\pi} \\Big\\lbrace r(s,\\pi(s)) + \\gamma \\sum_{s' \\in \\mathcal{S}} \\mathbb{P}(s'\\vert s,\\pi(s)) V^*(s') \\Big\\rbrace\n",
    "\\end{equation}\n",
    "or equivalently in terms of the Bellman operator $\\mathcal{L}$ \n",
    "\\begin{equation}\n",
    "V^* =  \\mathcal{L}(V^*)\n",
    "\\end{equation}\n",
    "where \n",
    "\\begin{equation}\n",
    "   \\forall s \\in \\mathcal{S} \\qquad  \\mathcal{L}(V)(s) = \\max_{\\pi} \\Big\\lbrace r(s,\\pi(s)) + \\gamma \\sum_{s' \\in \\mathcal{S}} \\mathbb{P}(s'\\vert s,\\pi(s)) V(s') \\Big\\rbrace. \n",
    "\\end{equation}\n",
    "Value iteration solves the Bellman equation described above. This method is implemented as `maze.value_iteration` in the file [maze.py]().\n",
    "\n",
    "> **Note:** Recall that the mapping $\\mathcal{L}$ is a contraction, therefore value iteration converges. To achieve an $\\varepsilon>0$ approximation (i.e. $\\Vert V^* - V_{n+1} \\Vert \\le \\varepsilon$),\n",
    " the stopping criterion of value iteration is $\\Vert V - \\mathcal{L}(V) \\Vert < \\frac{1-\\gamma}{\\gamma}\\varepsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount Factor \n",
    "gamma   = 0.95; \n",
    "# Accuracy treshold \n",
    "epsilon = 0.0001;\n",
    "V, policy = mz.value_iteration(env, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'ValIter';\n",
    "start  = (0,0);\n",
    "path = env.simulate(start, policy, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random rewards \n",
    "\n",
    "### The new MDP formulation \n",
    "As stated in the problem statement, we only modify the rewards $\\mathcal{R}$ to be random. In fact we will only need to modify the rewards corresponding to the state action pair $(s,a)$ that lead to either the cell R1 or R2.\n",
    "#### Rewards $\\mathcal{R}$\n",
    "The objective of the player is to find the exit of the maze while avoiding the obstacles.    \n",
    "   - If at state $s$, taking action $a$, leads to the cell R1 then the reward is random according to the following     $$ R(s,a) = \\begin{cases}\n",
    "            -7 \\quad \\textrm{ w.p. } 0.5 \\\\\n",
    "            -1 \\quad \\textrm{ w.p. } 0.5\n",
    "            \\end{cases} \n",
    "     $$\n",
    "   - If at state $s$, taking action $a$, leads to the cell R2 then the reward is random according to the following \n",
    "     $$ R(s,a) = \\begin{cases}\n",
    "            -2 \\quad \\textrm{ w.p. } 0.5 \\\\\n",
    "            -1 \\quad \\textrm{ w.p. } 0.5\n",
    "            \\end{cases} \n",
    "     $$\n",
    "   - The remaining rewards remain deterministic and with the same values as in the previous formulation.\n",
    "\n",
    "> **Note**: The fact that you stay in a cell for a number of rounds $n$ means that you are forced to incur the reward of ending up in that state for an additional $n$ times. Thus, instead of modifying the transition probabilities, we can modify the reward of ending up at that round by multiplying it by $n + 1$.  \n",
    "\n",
    "### Solving the new MDP \n",
    "As mentioned in the appendix [random_rewards.pdf]() (see in canvas), when solving the problem we will only have to look at the average rewards instead of the realization of the rewards, and the methods implemented for the previous case remain unchanged.  \n",
    "\n",
    "> **Note**: In the implementation, the only change will be the rewards. In addition, the policies we obtain remain deterministic. However, when running a policy the accumulated reward is random, but its average over multiple repetitions should converge to the value function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [ 0, 0, 1, 0, 0, 0,  0],\n",
    "    [ 0, 0, 1, 0, 0, 0,  0],\n",
    "    [ 0, 0, 1, 0, 0, 0,  0],\n",
    "    [ 0, 0, 0, 0, 0, 0, -1],\n",
    "    [ 0, 1, 1, 1, 1, 1,  0],\n",
    "    [-6, 0, 0, 0, 0, 2,  0]\n",
    "])\n",
    "# with the convention \n",
    "#  0 = empty cell\n",
    "#  1 = obstacle\n",
    "#  2 = exit of the Maze\n",
    "# -n = trapped cell with probability 0.5. If the cell is trapped the player must stay there for n times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mz.draw_maze(maze);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic programming \n",
    "\n",
    "Run the following python code to obtain the optimal solution of the newly formulated MDP with dynamic programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment maze\n",
    "env = mz.Maze(maze, random_rewards=True)\n",
    "# env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finite horizon\n",
    "horizon = 15\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy= mz.dynamic_programming(env,horizon);\n",
    "# Simulate the shortest path starting from position A\n",
    "method = 'DynProg';\n",
    "start  = (0,0);\n",
    "path = env.simulate(start, policy, method);\n",
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The animation does not illustrate the event where the player is trapped as it assumes average rewards. Nonetheless, the shown policy is the optimal one.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value iteration  \n",
    "\n",
    "Run the following python code to obtain the optimal solution of the newly formulated MDP with value iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAFoCAYAAABqqe1MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO8ElEQVR4nO3deayldX3H8c/3zsBcNgE3ZNBCtdoqi0uh1kqNDW4Djtq6tC6Y2mowNVWrJtatqE2siY0mthopxtY6VStiUVzi0gqCotZY3KK2alTqKJZN1oGB++sf50AucGe543y9c4+vV0Jy55znec7vd86Z877P77l3qDFGAGB3m1vpAQAwmwQGgBYCA0ALgQGghcAA0EJgAGghMKwKVfXqqto0/fpXqurqqlrzC3rsb1TVwxuOe0RVjapau4v7v7yq3r67xwW7yy69sWFXVdX3kxyS5KYk1yT5aJI/H2NcvbPHGGP8MMn+LQNc+vGO/EU91rZMA7dpjHH3m28bY7xu5UYEO+YMhpWwcYyxf5IHJTkuyStXeDxAA4FhxYwxfpTkY0mOSpKqWl9VH6qqy6rqO1X1nKX2u+3SUlXdsar+sao2V9XlVXXW9PavV9XGRfvtVVWXVNUDljjmnavqw1V1xfTxz6uquel936+qR0y/fnVVnVFVm6rqqqr6WlXdp6peVlU/raqLqupRi457y76L9t+0jXk9q6q+OT3u96rqlOnt+02fp/XTpcGrp8/VrY5VVY+bLuddUVXnVNV9bzOOl1TVV6vqZ1X1r1U1v+NXCXadwLBiquoeSU5M8l/Tm96T5H+TrE/ypCSvq6oTduJQ70qyb5Ijk9w1yZumt/9zkmcs2u7EJD8eY1y4xDFePH3su2SyhPfyJNv6d5Q2Th/z4OnYP57J36XDkrw2yWk7Meal/DTJY5PcIcmzkrypqh40xrgmyYYkm8cY+0//27x4x6q6TybP3wunc/hokrOrau9Fmz0lyWOS/GqSY5L88S6OE3aKwLASzqqqK5Kcn+TcTEJyjyTHJ3npGGPLNAJvT3Ly9g5UVYdm8uH73DHG5WOMrWOMc6d3b0pyYlXdYfrnkzMJw1K2Jjk0yeHTY5w3tv0P9Z03xvj4GOPGJGdk8oH++jHG1iTvTXJEVR2046fh1sYYHxljfHdMnJvkE0l+dyd3/8MkHxljfHI6jr9Nsk+S31m0zZvHGJvHGJclOTvJ7c7kYHcSGFbCE8YYB40xDh9j/NkY47pMzlouG2NctWi7H2RyVrA995jud/lt75h+l//ZJE+cfuBvSPIv2zjOG5J8J8knpstTf7mdx7x40dfXJblkjHHToj8nu/BDCFW1oao+P12iuyKTM6477+Tu6zN5vpIkY4yFJBfl1s/fTxZ9fe2ujBGWQ2DYU2xOcseqOmDRbb+S5Ec72O+i6X7bOmN4ZybLZE9OcsH0us/tjDGuGmO8eIxxz0yWwF60k8tzO3JNJst3N7vbUhtV1bokZ2Zy5nHIGOOgTJa56uYh7uBxNic5fNHxKpP47uj5gzYCwx5hjHFRks8l+Zuqmq+qY5L8abZ9xnHzfj/O5AL4W6vq4OmF/Ict2uSsTH5a7QWZXJNZUlU9tqp+bfrBfGUmP0Z907a2X4YLk/zRdFzHZnJtaSl7J1mX5P+S3FhVG5I8atH9Fye5U1UduI3935fkpKo6oar2yuSa0vWZPKewIgSGPclTkxyRyXfj/5bk1DHGJ3div5MzuYbyrUwulL/w5jumy29nZnJh+wPbOca9k3wqydVJLkjy1jHGOcuewe29Ksm9klye5DVJ3r3URtOlwednEorLkzwtyYcW3f+tTC7if2/6U2Lrb7P/tzM5U/u7JJdkcha2cYxxw26YA+yS8j8cY9ZV1V8luc8Y4xk73BjYbfwmPzOtqu6YyVLbdn8aDdj9LJExs6a/qHlRko+NMT6z0uOBXzaWyABo4QwGgBYCA0CLZV3kX7NmzVhYWOgay4qbm5vLLM9vls36a2d+q9uMz2+MMZY8WVnWNZiq2s4/z7T6VVVmdX6T3x+cbbP62iWz/d5MzG81m85tyQ8YS2QAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQIu1y9l4bm4uVdU1lhU3Pz8/0/ObZevWrZvp127W35vmt3ptb141xljOgcZytl9tqiqzOr9ZfXMvNquvXTLb783E/Faz6dyW/ICxRAZAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABosXY5G8/NzaWqusay4ubn52d6frNs3bp1M/3azfp70/xWr+3Nq8YYyznQWM72q01VZVbnN6tv7sVm9bVLZvu9mZjfajad25IfMJbIAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC3WLmfjubm5VFXXWFbc/Pz8zM5vfn4+W7ZsWelhtJnl1y4xv9Vufu91Mzu/7c1rWYFZWFjIGOPnHtCeqqpmdn6zPLfE/Fa7X4r5nf+llR5Gizr+2G3eZ4kMgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGhRY4yd3njNmjVjYWGhcTgAs2fdunW5/vrrV3oYLaoqCwsLteR9ywlMVY3lbL/aVC35HAH83Gb1s7OqMsZY8sPTEhkALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGgxdrlbDxXlarqGsuKm5+fz5YtW1Z6GC1meW6J+a12e83vla1btq70MNrMz8/P7Gfn9ua1rMAsjJFx/pd+7gHtqer4YzPGWOlhtKiqmZ1bYn6rXVXlLTedttLDaPO8NafM7Ou3vcBYIgOghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALdau9AAAtuWCf/pcLjzzy9nvTvvl0CPX5/Djjsjmb2zOw5/3e7t8zIWFhczNTb63Pu9t5+Y3Hnm/3OVed9nl453+5NPynDNO2eX9Z5nAAHu04095WI5+7DE5/Ulvy+HHHZEkuWLzFfnMW8/JNZdek/s9+sgcdPeD8t/nfDuPfMmj8/4XvS8n/MUj8rUPfy0//Z+Lc+3l12bjXz8+Z7/qg7nTEXfK+qMOywOf+KAkyZUXX5mt192QT73xk7nsB5dmnwP3ycbXPv6Wx/7KBy/M1z/81WzdsjUnnrox3z3/O9n/zvvn6Mcek3c89fQ85hUn5iff/HE+8pqzc8KLH5n5/edX4inaYwkMsEf77NvPz1c/9JU8+JkPueW2NWvncuP1N+aAQw7If777C3n2+07Jp9/8H7n2imuz5cot2efgffPFTRfkvo86Mkly0Zd/mCR56LOPz0GHHXy7x7jyJz/L4b95eO634ahb3f7Fd30+z3n/c3PpDy7NuX//6Rx65Ppb3b/+qMNyt/sempNO3bi7pz0TXIMB9mgPffbxefo/nJxjHnf/W277wqYv5OiNx+TRL9uQLVdtSZI84PcfmHc89fQ8+Jm/nYzkwPUH56RTN+ZJb3zKLfvOH7jPko/xhNf/Qe7663fLpj95Z6678rrb3V9VSZK91q3Nwo0LSZLrr7l+et/um+uscQYDrDr3fMg9c/5pn8n3PvfdrN178jF29MZj8u9v/GTu/bD7JEmO+K0j8r7nvydjJA951kO3e7xPveETufqSq7PvHffL3vvufcvtxz39wXn3czflhmtvyIZXnpR1+6/LWS89M5d+/5Jc97NJiA445A4562UfyGNecaIlstuoMcbOb1w1xvlfahzOyqrjj81yno/VpKpmdm6J+a12VZW33HTaLu+/dcvWnPGC9+bIDUfn/k94wG4c2e7xvDWnzOzrN31vLnke5wwGWPX2mt8rTzvt5JUeBrfhGgwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALSoMcbOb1y1kKT6hrOyqirLeT5Wk1meW2J+q535rWpjjLHkycqyAgMAO8sSGQAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALf4foqg7eFuJ2EkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discount Factor \n",
    "gamma   = 0.95; \n",
    "# Accuracy treshold \n",
    "epsilon = 0.0001;\n",
    "V, policy = mz.value_iteration(env, gamma, epsilon)\n",
    "\n",
    "method = 'ValIter';\n",
    "start  = (0,0);\n",
    "path = env.simulate(start, policy, method)\n",
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 : Plucking berries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new MDP formulation \n",
    "\n",
    "In this problem, the introduction of weights is translated in our previous MDP formulation by a modification of the rewards $\\mathcal{R}$. This is done by simply setting $r(s,a)$ to $w_{ij}$ if being in state $s$ and taking action $a$ leads to being in th new state $s'=(i,j)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [ 0, 0, 1, 0, 0, 0,  0],\n",
    "    [ 0, 0, 1, 0, 0, 0,  0],\n",
    "    [ 0, 0, 1, 0, 0, 0,  0],\n",
    "    [ 0, 0, 0, 0, 0, 0,  0],\n",
    "    [ 0, 1, 1, 1, 1, 1,  0],\n",
    "    [ 0, 0, 0, 0, 0, 2,  0]\n",
    "])\n",
    "\n",
    "# Description of the weight matrix as a numpy array\n",
    "w = np.array([\n",
    "    [0,    1, -100,   10,   10,   10, 10],\n",
    "    [0,    1, -100,   10,    0,    0, 10],\n",
    "    [0,    1, -100,   10,    0,    0, 10],\n",
    "    [0,    1,    1,    1,    0,    0, 10],\n",
    "    [0, -100, -100, -100, -100, -100, 10],\n",
    "    [0,    0,    0,    0,    0,   11, 10]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment maze\n",
    "env = mz.Maze(maze, weights=w)\n",
    "# env.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic programming \n",
    "\n",
    "Run the following python code to obtain the optimal solution of the newly formulated MDP with dynamic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAFoCAYAAABqqe1MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO00lEQVR4nO3deayldX3H8c/3MjCXTTYVGbRMtdIqi0tLrdUaG9wGGLV1aV0wtdVgaqpWTaxbUZtYExtNbDVSjK11qhbEorhEsRUERW1icYvaqlGpo1g2WQcG7q9/nAO5wJ1h7jhf79zT1yshuXPO8zzn9zvnzHnf5/fcO9QYIwCwq82t9AAAmE0CA0ALgQGghcAA0EJgAGghMAC0EBhWhap6XVVtmn79S1V1bVXt8Qt67G9U1aMbjru+qkZVrdnJ/V9VVe/a1eOCXWWn3tiws6rq+0kOTXJLkuuSfDzJn40xrt3RY4wxfphkv5YBLv14R/2iHmtbpoHbNMa49623jTHeuHIjgrvmDIaVsHGMsV+ShyY5LslrVng8QAOBYcWMMX6U5BNJjk6SqlpXVR+pqiuq6jtV9fyl9rvj0lJVHVxV/1BVm6vqyqo6e3r716tq46L99qyqy6rqwUsc8+5V9dGqumr6+BdU1dz0vu9X1WOmX7+uqs6sqk1VdU1Vfa2qjqyqV1bVT6vqkqp63KLj3rbvov03bWNez62qb06P+72qOmV6+77T52nddGnw2ulzdbtjVdUTp8t5V1XVeVX1gDuM4+VV9dWq+llV/UtVzd/1qwQ7T2BYMVV1nyQnJPnP6U3vT/I/SdYleWqSN1bV8TtwqPcm2SfJUUnumeSt09v/KcmzF213QpIfjzEuXuIYL5s+9j0yWcJ7VZJt/TtKG6ePedB07J/M5O/S4UnekOS0HRjzUn6a5KQkd0vy3CRvraqHjjGuS7IhyeYxxn7T/zYv3rGqjszk+XvJdA4fT3JOVe21aLOnJ3lCkl9OcmySP9rJccIOERhWwtlVdVWSC5Ocn0lI7pPkkUleMcbYMo3Au5KcvL0DVdVhmXz4vmCMceUYY+sY4/zp3ZuSnFBVd5v++eRMwrCUrUkOS3LE9BgXjG3/Q30XjDE+Oca4OcmZmXygv2mMsTXJB5Ksr6oD7/ppuL0xxsfGGN8dE+cn+VSS39nB3f8gycfGGOdOx/E3SfZO8tuLtnnbGGPzGOOKJOckudOZHOxKAsNKePIY48AxxhFjjD8dY9yQyVnLFWOMaxZt94NMzgq25z7T/a684x3T7/I/l+Qp0w/8DUn+eRvHeXOS7yT51HR56i+285iXLvr6hiSXjTFuWfTnZCd+CKGqNlTVF6ZLdFdlcsZ19x3cfV0mz1eSZIyxkOSS3P75+8mir6/fmTHCcggMu4vNSQ6uqv0X3fZLSX50F/tdMt1vW2cM78lkmexpSS6aXve5kzHGNWOMl40x7pvJEthLd3B57q5cl8ny3a3utdRGVbU2yVmZnHkcOsY4MJNlrrp1iHfxOJuTHLHoeJVJfO/q+YM2AsNuYYxxSZLPJ/nrqpqvqmOT/Em2fcZx634/zuQC+Duq6qDphfxHLdrk7Ex+Wu3FmVyTWVJVnVRVvzL9YL46kx+jvmVb2y/DxUn+cDqu38jk2tJS9kqyNsn/Jrm5qjYkedyi+y9NckhVHbCN/c9IcmJVHV9Ve2ZyTenGTJ5TWBECw+7kGUnWZ/Ld+L8mOXWMce4O7HdyJtdQvpXJhfKX3HrHdPntrEwubH9oO8e4f5JPJ7k2yUVJ3jHGOG/ZM7iz1ya5X5Irk7w+yfuW2mi6NPiiTEJxZZJnJvnIovu/lclF/O9Nf0ps3R32/3YmZ2p/m+SyTM7CNo4xbtoFc4CdUv6HY8y6qvrLJEeOMZ59lxsDu4zf5GemVdXBmSy1bfen0YBdzxIZM2v6i5qXJPnEGOOzKz0e+P/GEhkALZzBANBCYABosayL/HvsscdYWFjoGsuKm5ubyyzPb5bN+mtnfqvbjM9vjDGWPFlZ1jWYqtrOP8+0+lVVZnV+k98fnG2z+tols/3eTMxvNZvObckPGEtkALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0CLNcvZeG5uLlXVNZYVNz8/P9Pzm2Vr166d6ddu1t+b5rd6bW9eNcZYzoHGcrZfbaoqszq/WX1zLzarr10y2+/NxPxWs+nclvyAsUQGQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaLFmORvPzc2lqrrGsuLm5+dnen6zbO3atTP92s36e9P8Vq/tzavGGMs50FjO9qtNVWVW5zerb+7FZvW1S2b7vZmY32o2nduSHzCWyABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAt1ixn47m5uVRV11hW3Pz8/MzOb35+Plu2bFnpYbSZ5dcuMb/Vbpbnt715LSswCwsLGWP83APaXVXVzM5vlueWmN9qZ36r1/YCY4kMgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGixZjkbz83Npaq6xrJbmOX5zfLcEvNb7WZ5fmvXrp3Z+W1vXjXGWM6BxnK2X21m9Q0ArLxZ/eysqowxlvzwtEQGQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaLFmORvPzc2lqrrGsuLm5+ezZcuWlR5Gi1meW2J+q92e83tm65atKz2MNvPz8zP72bm9eS0rMAsLCxlj/NwD2l1V1czOb5bnlpjfaldVefstp630MNq8cI9TZvb1215gLJEB0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBZrVnoAANty0T9+Phef9eXse8i+OeyodTniuPXZ/I3NefQLf3enj7mwsJC5ucn31he88/z82mMfmHvc7x47fbzTn3Zann/mKTu9/ywTGGC39shTHpVjTjo2pz/1nTniuPVJkqs2X5XPvuO8XHf5dXng44/Kgfc+MP913rfz2Jc/Ph986Rk5/s8fk6999Gv56X9fmuuvvD4b/+pJOee1H84h6w/JuqMPz0Oe8tAkydWXXp2tN9yUT7/l3Fzxg8uz9wF7Z+MbnnTbY3/lwxfn6x/9arZu2ZoTTt2Y7174nex39/1yzEnH5t3POD1PePUJ+ck3f5yPvf6cHP+yx2Z+v/mVeIp2WwID7NY+964L89WPfCUPe87Db7ttjzVzufnGm7P/ofvnP973xTzvjFPymbf9e66/6vpsuXpL9j5on3xp00V5wOOOSpJc8uUfJkke8bxH5sDDD7rTY1z9k5/liF8/Ig/ccPTtbv/Se7+Q53/wBbn8B5fn/L/7TA47at3t7l939OG51wMOy4mnbtzV054JrsEAu7VHPO+Redbfn5xjn/ig22774qYv5piNx+bxr9yQLddsSZI8+Pceknc/4/Q87Dm/lYzkgHUH5cRTN+apb3n6bfvOH7D3ko/x5Df9fu75q/fKpj9+T264+oY73V9VSZI9167Jws0LSZIbr7txet+um+uscQYDrDr3ffh9c+Fpn833Pv/drNlr8jF2zMZj829vOTf3f9SRSZL1v7k+Z7zo/RkjefhzH7Hd4336zZ/KtZddm30O3jd77bPXbbcf96yH5X0v2JSbrr8pG15zYtbutzZnv+KsXP79y3LDzyYh2v/Qu+XsV34oT3j1CZbI7qDGGDu+cdVYzvarTVVlVuc3y3NLzG+1q6q8/ZbTdnr/rVu25swXfyBHbTgmD3ryg3fhyHaNF+5xysy+ftP35pLncc5ggFVvz/k988zTTl7pYXAHrsEA0EJgAGghMAC0EBgAWggMAC0EBoAWAgNAC4EBoIXAANBCYABoITAAtBAYAFoIDAAtBAaAFgIDQAuBAaCFwADQQmAAaCEwALQQGABaCAwALQQGgBYCA0CLGmPs+MZVC0mqbzgrq6qynOdjNZnluSXmt9qZ36o2xhhLnqwsKzAAsKMskQHQQmAAaCEwALQQGABaCAwALQQGgBYCA0ALgQGghcAA0OL/AIUcLrRZsvf3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finite horizon\n",
    "horizon = 20\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy= mz.dynamic_programming(env,horizon);\n",
    "# Simulate the shortest path starting from position A\n",
    "method = 'DynProg';\n",
    "start  = (0,0);\n",
    "path = env.simulate(start, policy, method);\n",
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** By changing the horizon from $20$ to $12$ you should observe that the optimal policy changes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value iteration  \n",
    "\n",
    "Run the following python code to obtain the optimal solution of the newly formulated MDP with value iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discount Factor \n",
    "gamma   = 0.50; \n",
    "# Accuracy treshold \n",
    "epsilon = 0.001;\n",
    "V, policy = mz.value_iteration(env, gamma, epsilon)\n",
    "method = 'ValIter';\n",
    "start  = (0,0);\n",
    "path = env.simulate(start, policy, method)\n",
    "# Show the shortest path \n",
    "mz.animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 3: Bank Robber (Reloaded)\n",
    "\n",
    "#### State space $\\mathcal{S}$\n",
    "We model the state space as the set of all possible positions of the player and the minotaur in the maze. Note that we exclude states where the player is on an obstacles' position since this is an impossible state. We do, however, permit the player to be in the same position as the minotaur, as this possible (the reward for this state will reflect the fact that this is an undesirable state.\n",
    "\n",
    "$$\\mathcal{S} = \\big\\lbrace ((i_r,j_r),(i_p,j_p))\\big\\rbrace.$$\n",
    "> **Note:** $\\mathcal i_a and j_a$ represents the position of the agent. $\\mathcal i_m and j_m$ represents the position of the minotaur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Bank_Rob:\n",
    "    def __init__(self, maze, init_pos):\n",
    "        self.maze = maze\n",
    "        self.size = maze.shape\n",
    "        self.current_pos = start_pos\n",
    "        self.state = self.build_state()\n",
    "        self.action = ['still', 'left', 'right', 'up', 'down']\n",
    "        self.action_size = len(self.action)\n",
    "        \n",
    "    def build_state(self):\n",
    "        state_list = []\n",
    "        for i in range(self.size[0]):\n",
    "            for j in range(self.size[1]):\n",
    "                for k in range(self.size[0]):\n",
    "                    for l in range(self.size[1]):\n",
    "                        state_list.append([(i,j),(k,l)])\n",
    "                        \n",
    "        return state_list\n",
    "\n",
    "    def police_policy(self):\n",
    "        actions = self.action\n",
    "        pos = self.current_pos[1]\n",
    "        if pos[0] == 0:\n",
    "            actions.remove('left')\n",
    "        elif pos[0] == 3:\n",
    "            actions.remove('right')\n",
    "        if pos[1] == 0:\n",
    "            actions.remove('up')\n",
    "        elif pos[1] == 3:\n",
    "            actions.remove('down')\n",
    "        selector = random.randint(0,len(actions))\n",
    "        sel_action = actions[selector]\n",
    "        return sel_action\n",
    "\n",
    "    def robber_policy(self):\n",
    "        #TODO: how will we make a policy and apply here?\n",
    "        sel_action = random.randint(0,4)\n",
    "        return sel_action\n",
    "\n",
    "    def move(self, selected_action, current_position):\n",
    "        if selected_action == 'left':\n",
    "            current_position[0] -= 1\n",
    "        elif selected_action == 'right':\n",
    "            current_position[0] += 1\n",
    "        elif selected_action == 'up':\n",
    "            current_position[1] -= 1\n",
    "        elif selected_action  == 'down':\n",
    "            current_position[1] += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def check_reward(self):\n",
    "        pos_robber = self.current_pos[0] \n",
    "        pos_police = self.current_pos[1]\n",
    "        if pos_robber == pos_robber:\n",
    "            rwd = -10\n",
    "            keep_robbing = False\n",
    "        elif pos_robber == (1,1):\n",
    "            rwd = 1\n",
    "            keep_robbing = True\n",
    "        else :\n",
    "            rwd = 0\n",
    "            keep_robbing = True            \n",
    "        return rwd, keep_robbing\n",
    "    \n",
    "    def Q_learning(self):\n",
    "        #Todo: Q learning study and code it !!!!!!!!\n",
    "        keep_robbing = True\n",
    "        reward = 0\n",
    "        while(keep_robbing):\n",
    "            police_action = self.police_policy()\n",
    "            self.move(police_action, current_position[1])\n",
    "            collected_reward, keep_robbing = self.check_reward()\n",
    "            reward += collected_reward\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [ 0, 0, 0, 0],\n",
    "    [ 0, 1, 0, 0],\n",
    "    [ 0, 0, 0, 0],\n",
    "    [ 0, 0, 0, 0]\n",
    "])\n",
    "start_pos = [(0,0),(3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_bank = Bank_Rob(maze, start_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
